{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install fasttext\n",
        "!pip install grapheme"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6xg_6BJ1I6jr",
        "outputId": "f443501d-8994-487d-a63e-2250fd58ad86"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fasttext\n",
            "  Downloading fasttext-0.9.3.tar.gz (73 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/73.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.4/73.4 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pybind11>=2.2 (from fasttext)\n",
            "  Using cached pybind11-2.13.1-py3-none-any.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from fasttext) (71.0.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fasttext) (1.26.4)\n",
            "Using cached pybind11-2.13.1-py3-none-any.whl (238 kB)\n",
            "Building wheels for collected packages: fasttext\n",
            "  Building wheel for fasttext (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fasttext: filename=fasttext-0.9.3-cp310-cp310-linux_x86_64.whl size=4246767 sha256=9677e6c247ad34d080c5f875b06766c3484fb3d23372c4c7b9d652b1f084f9c2\n",
            "  Stored in directory: /root/.cache/pip/wheels/0d/a2/00/81db54d3e6a8199b829d58e02cec2ddb20ce3e59fad8d3c92a\n",
            "Successfully built fasttext\n",
            "Installing collected packages: pybind11, fasttext\n",
            "Successfully installed fasttext-0.9.3 pybind11-2.13.1\n",
            "Collecting grapheme\n",
            "  Downloading grapheme-0.6.0.tar.gz (207 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: grapheme\n",
            "  Building wheel for grapheme (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for grapheme: filename=grapheme-0.6.0-py3-none-any.whl size=210078 sha256=ffa774afe19fcc20d5bcc471e867236cb9a1dd88a94b47390b7cc3094e54f265\n",
            "  Stored in directory: /root/.cache/pip/wheels/01/e1/49/37e6bde9886439057450c494a79b0bef8bbe897a54aebfc757\n",
            "Successfully built grapheme\n",
            "Installing collected packages: grapheme\n",
            "Successfully installed grapheme-0.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "-A-D-QRjBrJB"
      },
      "outputs": [],
      "source": [
        "import fasttext\n",
        "model_path = '/content/drive/MyDrive/cc.mr.300.bin'\n",
        "model = fasttext.load_model(model_path)\n",
        "import grapheme"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# final prediction function\n",
        "# making  a function for word prediction of 2 or more characters\n",
        "def word_sorting(similar_words_, no_of_input_characters, input_characters):\n",
        "  final_list = []\n",
        "  if no_of_input_characters >= 2:\n",
        "    matched_list=[i for i in similar_words_ if len(list(grapheme.graphemes(i))) == no_of_input_characters] # match number of alphabets\n",
        "    for i in matched_list:\n",
        "        alphabet_break = list(grapheme.graphemes(i))\n",
        "        result_set = set(alphabet_break) &  set(input_characters)\n",
        "        if no_of_input_characters == 2:\n",
        "          if len(result_set) >= 0.4*no_of_input_characters:\n",
        "            final_list.append(i)\n",
        "        if no_of_input_characters >= 3:\n",
        "          if len(result_set) >= 0.3*no_of_input_characters:\n",
        "            final_list.append(i)\n",
        "  return final_list\n",
        "\n",
        "def word_sorting_2(similar_words_2, no_of_input_characters, input_characters,input_characters_2):\n",
        "  final_list = []\n",
        "  if no_of_input_characters >= 2:\n",
        "    matched_list=[i for i in similar_words_2 if len(list(grapheme.graphemes(i))) == no_of_input_characters] # match number of alphabets\n",
        "    for i in matched_list:\n",
        "        # alphabet_break = list(grapheme.graphemes(i))\n",
        "        # result_set = set(alphabet_break) &  set(input_characters)\n",
        "        if no_of_input_characters == 2:\n",
        "          alphabet_break = list(i)\n",
        "          result_set = set(alphabet_break) & set(list(word))\n",
        "          if len(result_set) >= 0.3*no_of_input_characters:\n",
        "            final_list.append(i)\n",
        "          # if len(result_set) >= 0.3*no_of_input_characters:\n",
        "          #   final_list.append(i)\n",
        "        if no_of_input_characters >= 3:\n",
        "          alphabet_break = list(grapheme.graphemes(i))\n",
        "          result_set = set(alphabet_break) &  set(input_characters)\n",
        "          if len(result_set) >= 0.4*no_of_input_characters:\n",
        "            final_list.append(i)\n",
        "  return final_list\n",
        "\n",
        "def word_prediction(word):\n",
        "  similar_words = model.get_nearest_neighbors(word, k=5000)\n",
        "  indexed_word_list = [(i, word) for i, word in enumerate(similar_words)]\n",
        "  input_characters_2 = list(word)\n",
        "  input_characters = list(grapheme.graphemes(word))\n",
        "  no_of_input_characters_2 = len(input_characters_2)\n",
        "  no_of_input_characters = len(input_characters)\n",
        "  marathi_characters = ['अ', 'आ', 'इ', 'ई', 'उ', 'ऊ', 'ऋ', 'ऌ', 'ए', 'ऐ', 'ओ', 'औ', 'अं', 'अः', 'क', 'ख', 'ग', 'घ', 'ङ', 'च', 'छ', 'ज', 'झ', 'ञ', 'ट', 'ठ', 'ड', 'ढ', 'ण', 'त', 'थ', 'द', 'ध', 'न', 'प', 'फ', 'ब', 'भ', 'म', 'य', 'र', 'ल', 'व', 'श', 'ष', 'स', 'ह', 'ळ','क्ष', 'त्र', 'ज्ञ', 'श्र']\n",
        "  vowel_diacritics = ['ा', 'ि', 'ी', 'ु', 'ू', 'ृ', 'ॄ', 'ॅ', 'े', 'ै', 'ॉ', 'ो', 'ौ', '्', 'ं', 'ः', 'ँ']\n",
        "  all_characters = set(marathi_characters + vowel_diacritics)\n",
        "  first_character = list(set(marathi_characters) & set(list(list(grapheme.graphemes(word)))[0]))[0]\n",
        "  similar_words_2 = [i[1][1] for i in indexed_word_list] #extract words\n",
        "  similar_words_2 = [j for j in similar_words_2 if set(list(j)).issubset(all_characters) is True] # remove non marathi words\n",
        "  similar_words_2 = [j for j in similar_words_2 if list(list(grapheme.graphemes(j))[0])[0] == first_character] # match first character\n",
        "\n",
        "  final_list = []\n",
        "  if no_of_input_characters == 1:\n",
        "    char_list = list(word)\n",
        "    first_character = [char for char in char_list if char not in vowel_diacritics][0]\n",
        "    similar_words_2 = [list(grapheme.graphemes(k))[0] for k in similar_words_2]\n",
        "    for j in similar_words_2:\n",
        "      if first_character in list(j)[0]:\n",
        "        final_list.append(j)\n",
        "\n",
        "  if no_of_input_characters >= 2:\n",
        "    final_list = word_sorting(similar_words_2, no_of_input_characters, input_characters) #\n",
        "  seen = set()\n",
        "  unique_list = []\n",
        "  if len(final_list) !=0:\n",
        "    for item in final_list:\n",
        "        if item not in seen:\n",
        "            unique_list.append(item)\n",
        "            seen.add(item)\n",
        "  while word in unique_list:\n",
        "    unique_list.remove(word)\n",
        "  final_list_2 = unique_list[:10] # how many results to show\n",
        "# part 2 for less options\n",
        "  if len(final_list_2) <= 6 & no_of_input_characters >1 :\n",
        "    similar_words_3 = [\"\".join(list(grapheme.graphemes(i))[:no_of_input_characters]) for i in similar_words_2]\n",
        "    final_list = word_sorting_2(similar_words_2, no_of_input_characters, input_characters, input_characters_2)\n",
        "    seen = set()\n",
        "    unique_list = []\n",
        "    if len(final_list) !=0:\n",
        "      for item in final_list:\n",
        "        if item not in seen:\n",
        "          unique_list.append(item)\n",
        "          seen.add(item)\n",
        "    for i in unique_list:\n",
        "      final_list_2.append(i)\n",
        "      while word in final_list:\n",
        "        final_list_2.remove(word)\n",
        "    final_list_2 = unique_list[:10]# how many results to show\n",
        "  return final_list_2"
      ],
      "metadata": {
        "id": "ilkS7GzXxxBU"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rINYzGmwJ_9Q",
        "outputId": "a819fce4-17ea-4cf1-9a17-3b45835f6cdd"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word = 'खात्री'\n",
        "# word = 'शांती'\n",
        "# word = 'विदर्भ'\n",
        "# word = 'औषध'\n",
        "# word = 'जिल्हा'\n",
        "# word = 'मंत्री'\n",
        "# word = 'प्रधानमंत्र'\n",
        "# word = 'शाळा'\n",
        "word_prediction(word)\n",
        "# model.get_nearest_neighbors(word, k=500)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KwzTibPXNjkX",
        "outputId": "2dcf289b-73f1-4cf6-fa71-ca6cd3758f88"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['खात्रि', 'खातरी', 'खातेस', 'खातेच']"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-wTmqL6OK7n0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}